# -*- coding: utf-8 -*-
"""Tytanic_01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E0NNolkAZAnB2_uoRpGMkHz44Comjx-_
"""

import pandas
import numpy
import matplotlib
import sklearn

print(pandas.__version__)
print(numpy.__version__)
print(matplotlib.__version__)
print(sklearn.__version__)

print(numpy.__version__)

from google.colab import files
uploaded = files.upload()



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

train_set = pd.read_csv("train.csv")
test_set = pd.read_csv("test.csv")

train_set.head(2)

test_set.head(2)

fig = plt.figure(figsize=(12,4))
ax1 = fig.add_subplot(121)
ax2 = fig.add_subplot(122)

PClassPlot = train_set["Survived"].groupby(train_set["Pclass"]).mean()
ax1.bar(x=PClassPlot.index, height=PClassPlot.values)
ax1.set_ylabel("Survival Rate")
ax1.set_xlabel("PClass")
ax1.set_xticks(PClassPlot.index)
ax1.set_yticks(np.arange(0,1.1,.1))
ax1.set_title("Class and Survival Rate")

GenderPlot = train_set["Survived"].groupby(train_set["Sex"]).mean()
ax2.bar(x=GenderPlot.index, height=GenderPlot.values)
ax2.set_ylabel("Survival Rate")
ax2.set_xlabel("Gender")
ax2.set_xticks(GenderPlot.index)
ax2.set_yticks(np.arange(0,1.1,.1))
ax2.set_title("Gender and Survival Rate")

fig = plt.figure(figsize=(12,4))
ax1 = fig.add_subplot(121)
ax2 = fig.add_subplot(122)

SiblingPlot = train_set["Survived"].groupby(train_set["SibSp"]).mean()
ax1.bar(x=SiblingPlot.index, height=SiblingPlot.values)
ax1.set_ylabel("Survival Rate")
ax1.set_xlabel("Total Siblings")
ax1.set_xticks(SiblingPlot.index)
ax1.set_yticks(np.arange(0, 1.1, .1))
ax1.set_title("Total Siblings and Survival Rate")

ParchPlot = train_set["Survived"].groupby(train_set["Parch"]).mean()
ax2.bar(x=ParchPlot.index, height=ParchPlot.values, width=.8, color="Teal")
ax2.set_ylabel("Survival Rate")
ax2.set_xlabel("Number of Parents and Children abroad")
ax2.set_xticks(ParchPlot.index)
ax2.set_yticks(np.arange(0,1.1,.1))
ax2.set_title("Number of Parents and Children abroad and Survival Rate")

train_set.isnull().sum()

train_set["Age"].fillna(train_set["Age"].median(), inplace=True)
train_set["Embarked"].fillna("C",inplace=True)

train_set["Sex"].head()

labelencoder=LabelEncoder()
train_set["Sex"]=labelencoder.fit_transform(train_set["Sex"])
train_set["Sex"].head()

Embarked = pd.get_dummies(train_set["Embarked"], drop_first=True)
Embarked.columns = ["Embarked-Q", "Embarked-S"]

Pclass = pd.get_dummies(train_set["Pclass"], drop_first=True)
Pclass.columns = ["Pclass2","Pclass3"]

Embarked.head()

Pclass.head()

train_set["Age_Cat"]=pd.qcut(train_set["Age"],4)
AgePlot = train_set["Survived"].groupby(train_set["Age_Cat"]).mean()
AgePlot

train_set["Fare_Cat"] = pd.qcut(train_set["Fare"],6)
FarePlot = train_set["Survived"].groupby(train_set["Fare_Cat"]).mean()
FarePlot

train_set["Total Family"] = train_set["SibSp"] + train_set["Parch"]
FamilyPlot = train_set["Survived"].groupby(train_set["Total Family"]).mean()
FamilyPlot

train_set["Alone"] = np.where(train_set["Total Family"]==0, 1, 0)
AlonePlot =train_set["Survived"].groupby(train_set["Alone"]).mean()
AlonePlot

train_set["Title"] = train_set.Name.str.extract(r",\s*([^\.]*)\s*\.", expand=False)

train_set["Title"].unique()

Mr = ["Mr"]
Crew1 = ["Don","Rev","Capt"]
Crew2 = ["Major", "Col", "Dr"]
Women_Masters = ["Mrs", "Miss", "Master"]
Affluence = ["Mme", "Ms", "Lady", "Sir", "Mlle","the Countess", "Jonkheer"]

train_set["Title_Group"]= np.where(train_set["Title"] == Mr[0], "Mr", "Affluence")
train_set["Title_Group"]= np.where(train_set["Title"].isin(Crew1),"Crew1", train_set["Title_Group"])
train_set["Title_Group"]= np.where(train_set["Title"].isin(Crew2),"Crew2", train_set["Title_Group"])
train_set["Title_Group"]= np.where(train_set["Title"].isin(Women_Masters),"Women_Masters", train_set["Title_Group"])
train_set["Title_Group"]= np.where(train_set["Title"].isin(Affluence),"Affluence", train_set["Title_Group"])

TitlePlot = train_set["Survived"].groupby(train_set["Title_Group"]).mean()

TitlePlot

train_set["Age_Cat"] = pd.qcut(train_set["Age"],4,labels=["Age Group 1",
                                                         "Age Group 2",
                                                         "Age Group 3",
                                                         "Age Group 4"])
train_set["Fare_Cat"] = pd.qcut(train_set["Fare"],6,labels =["Fare Group 1",
                                                            "Fare Group 2",
                                                            "Fare Group 3",
                                                            "Fare Group 4",
                                                            "Fare Group 5",
                                                            "Fare Group 6"])

Age = pd.get_dummies(train_set["Age_Cat"], drop_first = True)
Fare = pd.get_dummies(train_set["Fare_Cat"], drop_first=True)
Title_Groups = pd.get_dummies(train_set["Title_Group"], drop_first=True)

Age.head()

Title_Groups.head()

Title_Groups.head()

# Age （年齢）、Fare （料金）、Title_Groups （敬称）をダミー変数へ変換
Age = pd.get_dummies(train_set['Age_Cat'], drop_first=True)
Fare = pd.get_dummies(train_set['Fare_Cat'], drop_first=True)
Title_Groups = pd.get_dummies(train_set['Title_Group'], drop_first=True)

# train_set （訓練データ）へ全てのダミー変数を連結
train_set = pd.concat([train_set, Pclass, Embarked, Age, Fare,Title_Groups], axis=1)

# 不要なカラムを訓練データから削除
train_set = train_set.drop(columns=['PassengerId','Pclass','Name','Embarked',
                                    'Fare','Ticket','Cabin','Age','Age_Cat',
                                    'Fare_Cat','Title','Title_Group'])

# 訓練データの全てのカラム（列）を表示
train_set.columns

X_train=train_set.drop(columns="Survived")
Y_train=train_set["Survived"]

# 欠損値の処理
test_set['Age'].fillna(test_set['Age'].median(), inplace=True)
test_set['Fare'].fillna(test_set['Fare'].median(), inplace=True)

# Sex(性別)の値を文字列から数値(0/1)へ変換
test_set['Sex'] = labelencoder.fit_transform(test_set['Sex'])

#PClass (旅客等級)とEmbarked (出発港)のダミー変数化
test_Pclass = pd.get_dummies(test_set['Pclass'],drop_first=True)
test_Pclass.columns =['PClass2','PClass3']
test_Embarked = pd.get_dummies(test_set['Embarked'],drop_first=True)
test_Embarked.columns = ['Embarked-Q','Embarked-S']

# 特徴量エンジニアリング
test_set['Age_Cat'] = pd.qcut(test_set['Age'],4)
Age_cat = pd.get_dummies(test_set['Age_Cat'], drop_first=True)
Age_cat.columns = ['Age Group 2','Age Group 3','Age Group 4']
test_set['Fare_Cat'] = pd.qcut(test_set['Fare'],6)
Fare_cat = pd.get_dummies(test_set['Fare_Cat'], drop_first=True)
Fare_cat.columns = ['Fare Group 2','Fare Group 3','Fare Group 4','Fare Group 5','Fare Group 6']
test_set['Total Family'] = test_set['SibSp'] + test_set['Parch']
test_set['Alone'] = np.where(test_set['Total Family']==0, 1, 0)
test_set['Title'] = test_set.Name.str.extract(r',\s*([^\.]*)\s*\.', expand=False)
test_set['Title_Group'] = np.where(test_set['Title'] == Mr[0], 'Mr','Affluence')
test_set['Title_Group'] = np.where(test_set['Title'].isin(Crew1), 'Crew1', test_set['Title_Group'])
test_set['Title_Group'] = np.where(test_set['Title'].isin(Crew2), 'Crew2', test_set['Title_Group'])
test_set['Title_Group'] = np.where(test_set['Title'].isin(Women_Masters), 'Women_Masters', test_set['Title_Group'])
test_set['Title_Group'] = np.where(test_set['Title'].isin(Affluence), 'Affluence', test_set['Title_Group'])
Title_Groups_test = pd.get_dummies(test_set['Title_Group'], drop_first=True)
test_set = pd.concat([test_set, test_Pclass,test_Embarked, Age_cat,Fare_cat, Title_Groups_test],axis=1)
PassengerID = test_set['PassengerId']
test_set = test_set.drop(columns=['Fare','Fare_Cat','Age_Cat','Age',
                                  'Name','Pclass','Ticket','Cabin',
                                  'PassengerId','Embarked','Title_Group','Title'])

# ロジスティック回帰、ランダムフォレスト、サポートベクターマシン
LR = LogisticRegression()
RF = RandomForestClassifier()
SVM = SVC()

# データ処理ライブラリ
import pandas as pd
import numpy as np

# データ可視化ライブラリ
import matplotlib.pyplot as plt

# 機械学習ライブラリ
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# 交差検証のパラメータを設定
scores = []
modelnames = ['ロジスティック回帰','ランダムフォレスト','サポートベクターマシン']
models = [LR,RF,SVM]

# ループ処理で交差検証
for i in models:
    score = cross_val_score(i, X_train, y_train, scoring = 'accuracy', cv = 5).mean()
    scores.append(score)

# 結果を出力
pd.DataFrame(scores, index=modelnames,
            columns=['CV Scores']).sort_values(by = 'CV Scores', ascending=False)

RF.fit(X_train, Y_train)

y_pred = RF.predict(test_set)

my_solution = pd.DataFrame({'PassengerId':PassengerID,'Survived':y_pred})
my_solution = my_solution.set_index('PassengerId')
my_solution.to_csv('submit.csv')

# ランダムフォレストのハイパーパラメータの指定
param_grid = {'bootstrap': [True],
 'max_depth': [2,3,5,10,20,100],
 'min_samples_leaf': [3,4,5],
 'min_samples_split': [8,10,12],
 'n_estimators': [100]}

# グリッドサーチ（評価＝正解率）
grid_searchlog = GridSearchCV(RF, param_grid, cv=5, scoring='accuracy')

grid_searchlog.fit(X_train, Y_train)
grid_searchlog.best_params_

optimised_rf = grid_searchlog.best_estimator_
y_pred_final = optimised_rf.predict(test_set)

my_solution = pd.DataFrame({'PassengerId':PassengerID,'Survived':y_pred_final})
my_solution = my_solution.set_index('PassengerId')
my_solution.to_csv('submit_fin.csv')

